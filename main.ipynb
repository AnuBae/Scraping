{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Use teknik for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 17\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use informatika for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 10\n",
      "Data yang sudah ada: 31\n",
      "-------------------------------------------------------\n",
      "Use sistem for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 18\n",
      "Data yang sudah ada: 30\n",
      "-------------------------------------------------------\n",
      "Use komputer for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 18\n",
      "Data yang sudah ada: 34\n",
      "-------------------------------------------------------\n",
      "Use informasi for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 16\n",
      "Data yang sudah ada: 33\n",
      "-------------------------------------------------------\n",
      "Use back for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 21\n",
      "Data yang sudah ada: 40\n",
      "-------------------------------------------------------\n",
      "Use front for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 19\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use end for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 13\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use backend for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 18\n",
      "Data yang sudah ada: 37\n",
      "-------------------------------------------------------\n",
      "Use frontend for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "HTTP Error 502: Bad Gateway- retry scrapeDetail() for: https://www.jobstreet.co.id/id/job/front-end-developer-engineer-3684127?jobId=jobstreet-id-job-3684127&sectionRank=29&token=0~29ee61f0-0e22-4974-b1ee-20ecead5e2cc&fr=SRP%20Job%20Listing\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 21\n",
      "Data yang sudah ada: 34\n",
      "-------------------------------------------------------\n",
      "Use fullstack for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 22\n",
      "Data yang sudah ada: 36\n",
      "-------------------------------------------------------\n",
      "Use stack for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 21\n",
      "Data yang sudah ada: 42\n",
      "-------------------------------------------------------\n",
      "Use IT for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 14\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use CIO for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 5\n",
      "Data yang sudah ada: 31\n",
      "-------------------------------------------------------\n",
      "Use CTO for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 7\n",
      "Data yang sudah ada: 44\n",
      "-------------------------------------------------------\n",
      "Use Engineer for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 20\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use Software for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 19\n",
      "Data yang sudah ada: 35\n",
      "-------------------------------------------------------\n",
      "Use Network for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 14\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use Rekayasa for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 19\n",
      "Data yang sudah ada: 19\n",
      "-------------------------------------------------------\n",
      "Use Perangkat for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 21\n",
      "Data yang sudah ada: 31\n",
      "-------------------------------------------------------\n",
      "Use Lunak for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 20\n",
      "Data yang sudah ada: 31\n",
      "-------------------------------------------------------\n",
      "Use Networking for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 14\n",
      "Data yang sudah ada: 29\n",
      "-------------------------------------------------------\n",
      "Use pertamina for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 19\n",
      "Data yang sudah ada: 25\n",
      "-------------------------------------------------------\n",
      "Use kai for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 0\n",
      "Data yang sudah ada: 30\n",
      "-------------------------------------------------------\n",
      "Use jakarta for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 13\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use android for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 16\n",
      "Data yang sudah ada: 34\n",
      "-------------------------------------------------------\n",
      "Use ios for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 16\n",
      "Data yang sudah ada: 32\n",
      "-------------------------------------------------------\n",
      "Use quality for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 13\n",
      "Data yang sudah ada: 44\n",
      "-------------------------------------------------------\n",
      "Use assurance for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 10\n",
      "Data yang sudah ada: 45\n",
      "-------------------------------------------------------\n",
      "Use pusri for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 0\n",
      "Data yang sudah ada: 9\n",
      "-------------------------------------------------------\n",
      "Use fresh for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "HTTP Error 502: Bad Gateway- retry scrapeDetail() for: https://www.jobstreet.co.id/id/job/junior-it-staff-3699511?jobId=jobstreet-id-job-3699511&sectionRank=20&token=0~295d33e6-d5d7-4ddc-b16a-dc9ac2feddb3&fr=SRP%20Job%20Listing\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 13\n",
      "Data yang sudah ada: 32\n",
      "-------------------------------------------------------\n",
      "Use graduate for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n",
      "Scrape karir on progress\n",
      "Data yang ditambah: 10\n",
      "Data yang sudah ada: 32\n",
      "-------------------------------------------------------\n",
      "Use freelance for keyword\n",
      "-------------------------------------------------------\n",
      "Scrape glints on progress\n",
      "Scrape jobstreet on progress\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import mysql.connector\n",
    "import ssl\n",
    "\n",
    "# konksi nanti coba ditaruh diluar\n",
    "# koneksi\n",
    "db = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='',\n",
    "    database='UnNgGrape'\n",
    "    )\n",
    "cursor = db.cursor()\n",
    "\n",
    "class Scrape:\n",
    "    def __init__(self):\n",
    "        self.allKey = Scrape.getAllKeyword()\n",
    "        for key in self.allKey:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(\"Use \" + key[0] + \" for keyword\")\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            Scrape.scrapeMain(key[0])\n",
    "\n",
    "    def getAllKeyword():\n",
    "        cursor.execute(\"SELECT * FROM keyword\")\n",
    "        allKeyword = cursor.fetchall()\n",
    "\n",
    "        return allKeyword\n",
    "\n",
    "    def scrapeMain(keyword):\n",
    "        # inisialisasi array untuk menampung hasil data\n",
    "        asal_situs = []\n",
    "        title_lowongan = []\n",
    "        nama_perusahaan = []\n",
    "        lokasi_perusahaan = []\n",
    "        keterangan_lowongan = []\n",
    "        skill_lowongan = []\n",
    "        benefit_lowongan = []\n",
    "        deskripsi_lowongan = []\n",
    "        stem_detail = []\n",
    "        link_lowongan = []\n",
    "\n",
    "        # variable untuk hitung\n",
    "        add = 0\n",
    "        exist = 0\n",
    "\n",
    "        # loop scrape\n",
    "        cursor.execute(\"SELECT * FROM scrape\")\n",
    "        raw_scrape = cursor.fetchall()\n",
    "        for rowS in raw_scrape:\n",
    "            asal = rowS[0]\n",
    "            # scrape data\n",
    "            main_link1 = rowS[1]\n",
    "            main_link2 = rowS[2]\n",
    "            main_link = main_link1 + keyword + main_link2\n",
    "            tag_main = rowS[3]\n",
    "            tag_lowongan = rowS[4]\n",
    "            tag_lowongan_part = rowS[5]\n",
    "            tag_perusahaan = rowS[6]\n",
    "            tag_perusahaan_part = rowS[7]\n",
    "            tag_lokasi = rowS[8]\n",
    "            tag_lokasi_part = rowS[9]\n",
    "            tag_mainDetail = rowS[10]\n",
    "            tag_keterangan = rowS[11]\n",
    "            tag_skill = rowS[12]\n",
    "            tag_benefit = rowS[13]\n",
    "            tag_deskripsi = rowS[14]\n",
    "            breakDeskripsi = rowS[15]\n",
    "            raw_link = rowS[16]\n",
    "\n",
    "            print(\"Scrape \" + asal + \" on progress\")\n",
    "\n",
    "            try:\n",
    "                r = Request(main_link, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'})\n",
    "                gcontext = ssl.SSLContext()  # Only for gangstars\n",
    "                response = urlopen(r, context=gcontext).read()\n",
    "                soup = BeautifulSoup(response, \"lxml\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            jobList = soup.find_all(\"div\", tag_main)\n",
    "            for p in jobList:\n",
    "                # check the data already exists or not \n",
    "                link = raw_link+p.find('a').get('href')\n",
    "\n",
    "                # mengecek apakah data sudah ada atau belum\n",
    "                cursor.execute(\"SELECT * FROM lowongan WHERE link_lowongan = '\" + link + \"'\")\n",
    "                data = cursor.fetchall()\n",
    "                # if else untuk pengecekan input data\n",
    "                if data:\n",
    "                    exist += 1\n",
    "                else:\n",
    "                    add += 1\n",
    "\n",
    "                    lowongan = p.find(tag_lowongan_part, tag_lowongan).get_text().replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "                    # menggunakan try except karena ada beberapa perusahaan yang dirahasiakan\n",
    "                    try:\n",
    "                        perusahaan = p.find(tag_perusahaan_part, tag_perusahaan).get_text().replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "                    except:\n",
    "                        perusahaan = \"Perusahaan Dirahasiakan\"\n",
    "\n",
    "                    try:\n",
    "                        lokasi = p.find(tag_lokasi_part, tag_lokasi).get_text().replace(\"head office - \", \"\").replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "                    except:\n",
    "                        lokasi = \"-\"\n",
    "\n",
    "                    # try print return scrapeDetail\n",
    "                    keterangan, skill, benefit, deskripsi = Scrape.scrapeDetail(link, tag_mainDetail, tag_keterangan, tag_skill, tag_benefit, tag_deskripsi, breakDeskripsi)\n",
    "                    \n",
    "                    # stemming for detail\n",
    "                    raw_stem = lowongan + \" \" + perusahaan + \" \" + lokasi + \" \" + keterangan + \" \" + skill + \" \" + benefit + \" \" + deskripsi\n",
    "                    stem = Scrape.stemming(raw_stem)\n",
    "                    \n",
    "                    # save data to database\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO lowongan(asal_situs, title_lowongan, nama_perusahaan, lokasi_perusahaan, keterangan_lowongan, skill_lowongan, benefit_lowongan, deskripsi_lowongan, stem_detail, link_lowongan)\"\n",
    "                        \"VALUES ('\"+ asal +\"', '\"+ lowongan +\"', '\"+ perusahaan +\"', '\"+ lokasi +\"', '\"+ keterangan +\"', '\"+ skill +\"', '\"+ benefit +\"', '\"+ deskripsi  +\"', '\"+  stem +\"', '\"+ link +\"')\"\n",
    "                        )\n",
    "                    db.commit()\n",
    "\n",
    "                    # push to array penampung hasil data\n",
    "                    asal_situs.append(asal)\n",
    "                    title_lowongan.append(lowongan)\n",
    "                    nama_perusahaan.append(perusahaan)\n",
    "                    lokasi_perusahaan.append(lokasi)\n",
    "                    keterangan_lowongan.append(keterangan)\n",
    "                    skill_lowongan.append(skill)\n",
    "                    benefit_lowongan.append(benefit)\n",
    "                    deskripsi_lowongan.append(deskripsi)\n",
    "                    stem_detail.append(stem)\n",
    "                    link_lowongan.append(link)\n",
    "\n",
    "        # tampil data scrape\n",
    "        print(\"Data yang ditambah: \" + str(add))\n",
    "        print(\"Data yang sudah ada: \" + str(exist))\n",
    "\n",
    "        jobList_dict ={'asal':asal_situs, 'lowongan':title_lowongan, 'perusahaan':nama_perusahaan, 'lokasi':lokasi_perusahaan, 'keterangan':keterangan_lowongan, 'skill':skill_lowongan, 'benefit':benefit_lowongan, 'deskripsi':deskripsi_lowongan, 'stem':stem_detail, 'link':link_lowongan}\n",
    "        df = pd.DataFrame(jobList_dict,columns = ['asal', 'lowongan', 'perusahaan', 'lokasi', 'keterangan', 'skill', 'benefit', 'deskripsi', 'stem', 'link'])\n",
    "        # # simpan data ke file csv. HAPUUSSS\n",
    "        # df.to_csv(\"Jobseeker.csv\", sep=',')\n",
    "        \n",
    "        return df.sort_values('asal',ascending=True)\n",
    "\n",
    "    def scrapeDetail(linkDetail, tag_mainDetail, tag_keterangan, tag_skill, tag_benefit, tag_deskripsi, breakDeskripsi):\n",
    "        try:\n",
    "            # hit the URL and fetch data\n",
    "            r = Request(linkDetail, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'})\n",
    "            gcontext = ssl.SSLContext()  # Only for gangstars\n",
    "            response = urlopen(r, context=gcontext).read()\n",
    "            soup = BeautifulSoup(response, \"lxml\")\n",
    "        except Exception as e:\n",
    "            # retry in case of an error\n",
    "            print(str(e) + \"- retry scrapeDetail() for: \" + linkDetail)\n",
    "            return Scrape.scrapeDetail(linkDetail, tag_mainDetail, tag_keterangan, tag_skill, tag_benefit, tag_deskripsi, breakDeskripsi); \n",
    "\n",
    "        raw_detail = soup.find_all(\"div\", tag_mainDetail)\n",
    "        for p in raw_detail:\n",
    "            # menggunakan try except karena ada beberapa estimasi keterangan yang tidak terlampir\n",
    "            try:\n",
    "                raw_keterangan = p.find(\"div\", tag_keterangan ).get_text(separator=\". \").replace(\"Fungsi Kerja. \", \"\").replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "                nltk_tokens = nltk.sent_tokenize(raw_keterangan)\n",
    "                keterangan = \"\"\n",
    "\n",
    "                for x in nltk_tokens:\n",
    "                    if x == \"Lamar.\":\n",
    "                        break\n",
    "                    keterangan = keterangan + \" \" + x\n",
    "            except:\n",
    "                keterangan = \"-\"\n",
    "            \n",
    "            try:\n",
    "                skill = p.find(\"div\", tag_skill).get_text(separator=\" \").replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "            except:\n",
    "                skill = '-'\n",
    "            try:\n",
    "                benefit = p.find(\"div\", tag_benefit).get_text(separator=\" \").replace(\"Tunjangan dan keuntungan\", \"keuntungan:\").replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "            except:\n",
    "                benefit = '-'\n",
    "\n",
    "            # menggunakan try except karena ada beberapa deskripsi yang NoneType\n",
    "            try:\n",
    "                # replace untuk glints\n",
    "                raw_deskripsi = p.find(\"div\", tag_deskripsi ).get_text(separator=\". \").replace(\"Informasi Penting. Pastikan perusahaan yang kamu lamar resmi dengan memeriksa website dan lowongan kerja mereka.. Read Less.\", \"\").replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '').replace(\"\\r\\n\", \"\").replace(\"\\xa0\", \"\")\n",
    "                nltk_tokens = nltk.sent_tokenize(raw_deskripsi)\n",
    "                deskripsi = \"\"\n",
    "\n",
    "                for x in nltk_tokens:\n",
    "                    if x == breakDeskripsi:\n",
    "                        break\n",
    "                    deskripsi = deskripsi + \" \" + x\n",
    "\n",
    "                # remove punctuation from deskripsi\n",
    "                deskripsi = Scrape.removePunctuation(deskripsi)\n",
    "            except:\n",
    "                deskripsi = \"-\"\n",
    "            \n",
    "            # give to scrapeMain\n",
    "            return keterangan, skill, benefit, deskripsi\n",
    "\n",
    "    def removePunctuation(InputString):\n",
    "        # define punctuation\n",
    "        punctuations = '''!()-[]{};:=+`'\",<>./|\\?@#$%^&*_~'''\n",
    "\n",
    "        # remove punctuation from the string\n",
    "        no_punct = \"\"\n",
    "        for char in InputString:\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "            else:\n",
    "                no_punct = no_punct + \" \"\n",
    "        \n",
    "        return no_punct\n",
    "\n",
    "    def stemming(raw_stem):\n",
    "        # call remove punctuation\n",
    "        stem = Scrape.removePunctuation(raw_stem).lower()\n",
    "\n",
    "        # create stemmer\n",
    "        # nltk\n",
    "        ps = PorterStemmer()\n",
    "        # sastrawi\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        # stemming process\n",
    "        # nltk\n",
    "        words = word_tokenize(stem)\n",
    "        nltk_stemmer = \"\"\n",
    "        for w in words:\n",
    "            nltk_stemmer = nltk_stemmer + \" \" + ps.stem(w)\n",
    "        # sastrawi sekaligus return\n",
    "        return stemmer.stem(nltk_stemmer)\n",
    "\n",
    "# panggil classnya\n",
    "Scrape()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20583e63f217a0dfcf174d22b20139d81f6c3a56bcabde6374eeeb6eff50f61d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
